== Análise Léxica

.Objetivos do capítulo
____________________
Ao final deste capítulo você deverá ser capaz de:

* Entender a função do analisador léxico dentro de um compilador
* Descrever a estrutura léxica de uma linguagem usando expressões regulares
* Criar o analisador léxico para uma linguagem usando um gerador de analisadores
____________________

A análise léxica é a primeira etapa do compilador, e recebe o arquivo de 
entrada criado pelo usuário. O arquivo de entrada é geralmente armazenado 
como uma sequência de caracteres individuais que podem ser lidos. A análise 
léxica tem como função agrupar os caracteres individuais em _tokens_, que 
são as menores unidades com significado no programa-fonte. Um _token_ pode 
ser pensado como sendo similar a uma palavra. 

Podemos fazer uma analogia do processo de análise do compilador com o ato 
de ler um texto. Na leitura, nós não lemos e decodificamos individualmente 
cada letra; nosso cérebro lê e processa um texto uma palavra por vez. Isso 
é comprovado pelo fato que conseguimos entender um texto mesmo que as 
palavras tenham erros de ortografia ou mesmo sejam escritas de maneira 
diferente. 

A análise léxica faz com que as etapas seguintes do compilador possam 
trabalhar no nível das palavras, ao invés do nível dos caracteres 
individuais. Isso facilita bastante o trabalho das etapas posteriores. 
Na análise léxica também são realizadas algumas tarefas como remover 
comentários dos arquivos do programa-fonte e registrar em uma tabela
os nomes de identificadores usados no programa. Os detalhes de como 
isso é feito são o tópico deste capítulo. 

=== O Funcionamento da Análise Léxica

Como vimos, a análise léxica agrupa os caracteres do arquivo de entrada 
(que contém o programa-fonte) em _tokens_. Um _token_ é similar a uma 
palavra do texto de entrada e é composto por duas partes principais:

.  um _tipo_;
.  um _valor_ opcional. 

O tipo indica que espécie de ``palavra'' o _token_ representa: um número, 
um sinal de pontuação, um identificador (nome de variável ou função), etc. 
O valor é usado em alguns tipos de _tokens_ para armazenar alguma informação 
adicional necessária. Outras informações podem ser associadas a cada _token_, 
dependendo das necessidades do compilador. 
Um exemplo comum é a posição no arquivo de entrada (linha e coluna) onde 
o _token_ começa, o que ajuda no tratamento de erros. 

Um exemplo vai deixar essas ideias mais claras. Vamos usar uma 
linguagem simples para expressões aritméticas com operandos constantes, 
uma linguagem "de calculadora". Na linguagem são permitidos números inteiros 
(positivos ou negativos), parênteses, e as quatro operações aritméticas básicas, 
representadas pelos caracteres usuais:

* soma `+`
* subtração +-+
* multiplicação +*+
* divisão +/+

Os tipos de _tokens_ são: número, operador e pontuação (para representar os 
parênteses). Todos os três tipos precisam armazenar informação no campo de 
valor do _token_. Por exemplo, um _token_ do tipo número diz apenas que um 
número foi encontrado, e o valor do número é guardado no campo de valor 
do _token_. 

Um exemplo de programa nessa linguagem é o seguinte:

.Exemplo de expressão aritmética
----
42 + (675 * 31) - 20925
----

Neste exemplo, todos os _tokens_ de tipo número são formados por mais de 
um caractere, o maior tendo cinco caracteres (+20925+). O analisador 
léxico gera para esse exemplo a seguinte sequência de _tokens_:

[[tabela-seq-tokens]]
.Sequência de _tokens_ para o exemplo
[options="header", frame="topbot", grid="none"]
|====
|Lexema   | Tipo      | Valor 
|42       | Número    | 42
|`+`      | Operador  | SOMA
|+(+      | Pontuação | PARESQ
|675      | Número    | 675
|+*+      | Operador  | MULT
|31       | Número    | 31
|+)+      | Pontuação | PARDIR
|+-+      | Operador  | SUB
|20925    | Número    | 20925
|====

Um _lexema_ é a sequência de caracteres que dá origem a um _token_. No 
exemplo atual, o lexema +20925+ gera um _token_ de tipo número e 
valor 20925. Note que o lexema é um conjunto de caracteres, a _string_ 
+"20925"+, enquanto que o valor do token é o valor numérico 20925. 

Os valores dos _tokens_ de tipo operador representam que operador gerou 
o _token_, e os valores do tipo pontuação funcionam da mesma forma. Os 
valores são escritos em letra ção do analisador léxico esses valores são representados por 
constantes numéricas. 

Para tornar esse exemplo mais concreto, vamos examinar a estrutura da 
implementação do analisador léxico para essa linguagem simples. 

==== Implementação Manual de um Analisador Léxico

Para uma linguagem simples como a linguagem de expressões aritmética 
do exemplo, escrever um programa que faz a análise léxica não apresenta
grande dificuldade. Nesta seção vamos examinar as partes mais importantes
do analisador léxico para essa linguagem, pois vários elementos serão 
similares para linguagens mais complexas. 

O código fonte completo do analisador léxico para a linguagem de expressões 
pode ser encontrado no seguinte arquivo: 

.Código fonte
{gitrepo}/blob/master/livro/capitulos/code/cap2/exp_lexer.c[code/cap2/exp_lexer.c]

Aqui vamos analisar as principais partes deste programa. Começamos com a definição da 
estrutura que vai guardar os _tokens_:

[source, c]
.Definição de estrutura para _tokens_
----
typedef struct 
{
  int tipo;
  int valor;
} Token; 
----

Como vimos, um _token_ tem dois campos: o tipo do _token_ e um valor associado. Ambos 
os campos são inteiros, então definimos algumas constantes para representar os valores 
possíveis desses campos. As primeiras constantes especificam o tipo de _token_:

[source, c]
.Constantes que representam o tipo do _token_
----
#define TOK_NUM         0 
#define TOK_OP          1
#define TOK_PONT        2
----

Com relação ao valor, para números o valor do _token_ é apenas o valor do
número encontrado. Para operadores e pontuação, por outro lado, precisamos 
apenas de alguns valores para representar os quatro operadores e dois caracteres
de pontuação:

[source, c]
.Constantes para operadores e pontuação
----
#define SOMA            0
#define SUB             1
#define MULT            2
#define DIV             3

#define PARESQ          0
#define PARDIR          1
----

O código do analisador léxico usa algumas variáveis globais, para facilitar o 
entendimento. O programa funciona recebendo o programa de entrada como uma 
_string_ (normalmente um compilador recebe o programa de entrada em um arquivo).
As informações guardadas em variáveis globais são a _string_ 
contendo o código do programa de entrada, o tamanho dessa _string_ e a posição 
atual da análise dentro da _string_:

[source, c]
.Variáveis globais para guardar o estado da análise
----
// string que contem o codigo que esta em analise
char *codigo;

// tamanho da string com o codigo
int tamanho;

// guarda posicao atual no codigo
int pos;
----

A análise é iniciada ao chamar a função +inicia_analise+, que estabelece o 
valor inicial das variáveis globais:

[source, c]
.Função para inicializar a análise léxica
----
void inicializa_analise(char *prog)
{
  codigo = prog;
  tamanho = strlen(codigo);
  pos = 0;
}
----

A função +inicia_analise+ recebe uma _string_ contendo o código do programa 
de entrada como parâmetro (+prog+), e armazena um ponteiro para essa _string_
na variável global +codigo+; a função também estabelece o valor da variável 
global +tamanho+ e inicializa a posição atual na análise com valor zero. 

A análise léxica em si funciona de maneira incremental: ao invés de analisar 
todo o código de entrada de uma vez e retornar todo o fluxo de _tokens_, a 
função de análise retorna um _token_ de cada vez. Por isso, o nome da função 
que realiza a análise é +proximo_token+, e ela retorna o próximo _token_ na 
sequência a cada vez que é chamada. 

Vamos analisar a função +proximo_token+ por partes. Começando pelas variáveis
locais usadas pela função: 

[source, c]
.Função que realiza a análise léxica
----
Token *proximo_token(Token *tok)
{
  char c;
  char valor[200];    // string para obter valor de um numero
  int  vpos = 0;      // posicao na string de valor
----

Como indicado nos comentários, a _string_ +valor+ é usada para determinar o 
valor de um _token_ de tipo número. Isso é necessário porque a função de análise 
lê um caractere do número de cada vez; a variável +vpos+ é usada para guardar a 
posição atual na string +valor+. A variável +c+, de tipo caractere, guarda o 
caractere atualmente sendo lido do código de entrada. 

Na maioria das linguagens de programação, os espaços em branco não são 
significativos para o programa, e portanto o programador pode usar quantidades 
variáveis de espaço entre os _tokens_ do programa. Por isso, a primeira tarefa 
do analisador é pular todo o espaço em branco que for necessário para chegar até 
o primeiro caractere do próximo _token_. Isso é feito pela seguinte parte da 
função +proximo_token+:

[source, c]
.Código para pular o espaço em branco antes do próximo _token_
----
  c = le_caractere();
  while (isspace(c)) {
    c = le_caractere();
  }
----

A função +le_caractere+ é uma função auxiliar que obtém o próximo caractere do 
programa de entrada, atualizando a posição atual dentro da _string_ que contém 
o programa (para detalhes, veja o código-fonte completo do analisador). O código 
acima lê caracteres da entrada enquanto eles os caracteres lidos forem de espaço 
(espaço em branco, tabulação e caracteres de nova linha), usando a função 
+isspace+ da biblioteca padrão da linguagem C. Ao final desse _loop_, 
a variável +c+ vai conter o primeiro caractere do próximo _token_. 

A função de 
análise deve então usar esse caractere para determinar que tipo de _token_ está 
sendo lido, e continuar de acordo com o tipo. Nessa linguagem é possível 
determinar o tipo do _token_ olhando apenas para o seu primeiro caractere, mas 
em linguagens mais complexas isso geralmente não é possível. 

Se o primeiro caractere do _token_ for um dígito, a análise determina que o 
próximo _token_ é um número. O processo a seguir é ler os próximos caracteres 
enquanto forem dígitos, armazenando cada dígito lido na _string_ auxiliar 
+valor+. Ao final, o valor do _token_ é obtido através da conversão da 
string +valor+ para um número inteiro, usando a função +atoi()+:

[source, c]
.Leitura de um _token_ de tipo número
----
  if (isdigit(c)) {
    tok->tipo = TOK_NUM;
    valor[vpos++] = c;
    c = le_caractere();
    while (isdigit(c)) {
      valor[vpos++] = c;
      c = le_caractere();
    }
    // retorna o primeiro caractere que nao eh um digito
    // para ser lido como parte do proximo token
    pos--;
    // termina a string de valor com um caractere 0
    valor[vpos] = '\0';
    // converte string de valor para numero
    tok->valor = atoi(valor);
  }
----

Se o primeiro caractere não for um dígito, a análise testa se é um caractere 
de operador e, se for, apenas determina qual constante deve ser usada como 
valor do _token_:

[source, c]
.Leitura de um _token_ operador
----
  else if (strchr(ops, c) != NULL) {
    tok->tipo  = TOK_OP;
    tok->valor = operador(c);
  }
----

A condição no +if+ acima é uma forma mais curta de verificar se o caractere é um 
dos operadores, ao invés de usar quatro comparações. A constante global +ops+ é 
definida da seguinte forma:

[source, c]
.Conjunto de operadores da linguagem
----
const char *ops = "+-*/";
----

E a função +strchr+ da biblioteca padrão da linguagem C retorna um valor diferente 
de +NULL+ se o caractere +c+ faz parte da _string_ +ops+. A função auxiliar 
+operador+ apenas associa o caractere do operador com a constante numérica 
correspondente; por exemplo se +c+ for o caractere `+`, a função +operador+ 
retorna a constante +SOMA+. A definição da função +operador+ pode ser vista 
no código-fonte completo do analisador. 

A última possibilidade de _token_ válido para essa linguagem ocorre se o 
primeiro caractere for um parêntese. Nesse caso o tipo do _token_ é determinado 
como pontuação e o valor é a constante +PARESQ+ se o caractere lido foi +(+ e 
+PARDIR+ se o caractere lido foi +)+. Se o caractere não foi nenhuma das 
possibilidades anteriores (dígito, operador ou parêntese) a análise retorna o 
valor +NULL+ para indicar uma falha na análise. Isso pode ocorrer porque foi 
encontrado na entrada um caractere que não pertence à linguagem, ou porque a 
entrada chegou ao fim. Se não ocorreu uma falha de análise, a função deve 
retornar o _token_ que foi obtido da análise. Isso nos leva ao final da função 
+proximo_token+:

[source, c]
.Final da função de análise léxica
----
  else if (c == '(' || c == ')') {
    tok->tipo  = TOK_PONT;
    tok->valor = (c == '(' ? PARESQ : PARDIR);
  }
  else
    return NULL;

  return tok;
}
---- 

A função +proximo_token+ completa, reunindo os trechos vistos de forma 
separada, pode ser vista a seguir:

[source, c]
.Função completa que faz a análise léxica
----
Token *proximo_token(Token *tok)
{
  char c;
  char valor[200];    // string para obter valor de um numero
  int  vpos = 0;      // posicao na string de valor

  c = le_caractere();
  // pula todos os espacos em branco
  while (isspace(c)) {
    c = le_caractere();
  }

  if (isdigit(c)) {
    tok->tipo = TOK_NUM;
    valor[vpos++] = c;
    c = le_caractere();
    while (isdigit(c)) {
      valor[vpos++] = c;
      c = le_caractere();
    }
    // retorna o primeiro caractere que nao eh um digito
    // para ser lido como parte do proximo token
    pos--;
    // termina a string de valor com um caractere 0
    valor[vpos] = '\0';
    // converte string de valor para numero
    tok->valor = atoi(valor);
  }
  else if (strchr(ops, c) != NULL) {
    tok->tipo  = TOK_OP;
    tok->valor = operador(c);
  }
  else if (c == '(' || c == ')') {
    tok->tipo  = TOK_PONT;
    tok->valor = (c == '(' ? PARESQ : PARDIR);
  }
  else
    return NULL;

  return tok;
}
----

O código completo do analisador inclui algumas funções de impressão e uma 
função principal que lê o programa de entrada a partir do teclado e mostra 
a sequência de _tokens_ obtida desta entrada. A função principal é:

[source, c]
.Função principal do programa de análise léxica
----
int main(void)
{
  char  entrada[200];
  Token tok;

  printf("Analise Lexica para Expressoes\n");

  printf("Expressao: ");
  fgets(entrada, 200, stdin);

  inicializa_analise(entrada);

  printf("\n===== Analise =====\n");

  while (proximo_token(&tok) != NULL) {
    imprime_token(&tok);
  }

  printf("\n");

  return 0;
}
----

Executando esse programa para a expressão de exemplo que vimos anteriormente, 
obtemos a seguinte saida:

.Saída para a expressão 42 + (675 * 31) - 20925
----
Analise Lexica para Expressoes
Expressao: 42 + (675 * 31) - 20925

===== Analise =====
Tipo: Numero     -- Valor: 42
Tipo: Operador   -- Valor: SOMA
Tipo: Pontuacao  -- Valor: PARESQ
Tipo: Numero     -- Valor: 675
Tipo: Operador   -- Valor: MULT
Tipo: Numero     -- Valor: 31
Tipo: Pontuacao  -- Valor: PARDIR
Tipo: Operador   -- Valor: SUB
Tipo: Numero     -- Valor: 20925
----

A saída está de acordo com o que esperamos da análise léxica dessa linguagem, 
como pode ser visto na Tabela <<tabela-seq-tokens>>. 

Vimos que para uma linguagem simples como a de expressões, é fácil criar 
diretamente o analisador léxico necessário. Entretanto, à medida que a 
estrutura da linguagem se torna mais complexa (como ocorre nas linguagens de
programação real), a complexidade do analisador léxico vai crescendo e se 
torna difícil criar o analisador léxico sem ter alguma técnica sistemática 
para lidar com a complexidade. 

As técnicas que usaremos para isso são relacionadas a uma classe de linguagens 
formais conhecida como _linguagens regulares_. Essas técnicas são fundamentadas 
em uma teoria bem desenvolvida, e contam com ferramentas que automatizam a maior 
parte do processo de análise léxica. 

=== Linguagens Regulares e Expressões Regulares

As linguagens regulares são um tipo de linguagem formal que são frequentemente 
utilizadas para representar padrões simples de texto. Uma técnica de 
representação muito utilizada para as linguagens regulares são as chamadas 
_expressões regulares_. Bibliotecas que dão suporte ao uso de expressões 
regulares estão disponíveis na maioria das linguagens de programação e são
muito usadas para busca em textos e para validação de entrada textual (para 
formulários de entrada de dados, por exemplo). 

Uma outra técnica de representação usada para linguagens regulares são os 
_autômatos finitos_. Autômatos finitos e expressões regulares são equivalentes, 
ou seja, todo padrão que pode ser representado por uma técnica também pode ser 
representada pela outra. Os autômatos finitos podem ser utilizados para 
organizar os padrões léxicos de uma linguagem, facilitando a implementação 
direta de um analisador léxico para ela. Ou seja, com os autômatos finitos 
podemos criar analisadores léxicos para linguagens mais complexas, e de maneira 
mais sistemática e confiável do que vimos no exemplo da linguagem de expressões. 

Para criar um analisador léxico dessa forma devemos definir os autômatos finitos 
que representam os padrões associados a cada tipo de _token_, depois combinar 
esses autômatos em um único autômato, e então implementar o autômato finito 
resultante como um programa. Mais detalhes sobre como fazer isso podem ser 
encontrados em outros livros sobre compiladores, por exemplo o famoso 
``livro do dragão'' (Compiladores: Princípios, Técnicas e Ferramentas, 2^a^ 
edição, de Aho et al., editora Pearson/Addison-Wesley). 

Aqui vamos usar uma abordagem mais automatizada, criando analisadores léxicos 
a partir de ferramentas chamadas de _geradores de analisadores léxicos_. Esses 
geradores recebem como entrada uma especificação dos padrões que definem cada 
tipo de _token_, e criam na saída o código-fonte do analisador léxico. Criar 
analisadores usando um gerador é prático e temos um certo nível de garantia que 
o código gerado estará correto. Para usar um gerador, no entanto, é preciso saber 
como representar os padrões que definem tipos de _tokens_ da linguagem como 
expressões regulares. 

==== Expressões Regulares

As expressões regulares descrevem padrões simples de texto de forma compacta 
e sem ambiguidade. Por exemplo, o padrão que descreve todas as _strings_ 
formadas com caracteres +a+ e +b+ que começam com +a+ e terminam com +b+ pode 
ser escrito como a expressão regular `a(a|b)*b` (a construção dessa expressão 
será explicada em breve). 

Existem várias sintaxes e representações diferentes para expressões regulares, 
dependendo da linguagem ou biblioteca utilizada. Como vamos utilizar o 
gerador de analisadores flex, usaremos aqui a sintaxe usada nessa 
ferramenta. 

==== Expressões básicas 

Cada expressão regular (ER) é uma _string_ que representa um conjunto de 
_strings_; também podemos dizer que uma ER representa um _padrão_ que é 
satisfeito por um conjunto de _strings_. 

A maioria dos caracteres representam eles mesmos em uma expressão regular. 
Por exemplo, o caractere +a+ em uma ER representa o próprio caractere +a+. 
A ER +a+ representa um padrão que poderia ser descrito em português como 
``o conjunto de _strings_ que possuem um caractere +a+''. Obviamente só 
existe uma _string_ dessa forma: a _string_ +"a"+. Colocando um padrão 
após o outro realiza a _concatenação_ dos padrões. Começando com caracteres 
simples, se juntarmos um +a+ e um +b+ formamos a expressão +ab+, que 
representa a _string_ que contém um +a+ seguido por um +b+, ou seja, 
a _string_ +"ab"+.

Mas o poder das Expressões Regulares vem de alguns caracteres que não 
representam eles mesmos; esses são _caracteres especiais_. Um 
caractere especial bastante usado é o `*`, que representa zero ou mais 
repetições de um padrão. Por exemplo, a expressão +a*+ representa 
_strings_ com zero ou mais caracteres +a+. A _string_ vazia `""`
satisfaz esse padrão e corresponde a zero repetições; outras _strings_ 
satisfeitas pelo padrão são +"a"+, +"aa"+, +"aaa"+, etc. O asterisco 
representa zero ou mais repetições do padrão que vem antes, não só 
de um caractere: a expressão `(ab)*` representa `""`, +"ab"+, 
+"abab"+, +"ababab"+, etc. Mas pelas regras de precedência das 
expressões, `ab*` é o mesmo que `a(b*)`, que representa um +a+ 
seguido por zero ou mais caracteres +b+, e não é igual a `(ab)*`. 

Outro caractere especial importante é a barra vertical +|+, que representa 
opções nas partes de um padrão. Por exemplo +a|b+ representa +a+ ou +b+, 
ou seja, as _strings_ +"a"+ e +"b"+. 

Isso nos leva ao exemplo apresentado antes: `a(a|b)*b` é uma expressão 
regular formada por três partes concatenadas em sequência: +a+, depois 
`(a|b)*` e por fim +b+. Isso significa que uma _string_ que satisfaz 
essa expressão deve começar com um caractere +a+, seguido por caracteres 
que satisfazem o padrão `(a|b)*` e terminando com um caractere +b+. O 
padrão `(a|b)*` é satisfeito por zero ou mais repetições do padrão +(a|b)+, 
que por sua vez é um padrão que é satisfeito por caracteres +a+ ou +b+. Ou 
seja, `(a|b)*` é um padrão que representa zero ou mais repetições de 
caracteres +a+ ou +b+. Alguns exemplos de cadeias que são representadas 
pela expressão `a(a|b)*b`:

* +"ab"+ (zero repetições do padrão interno `(a|b)*`)
* +"aab"+
* +"abb"+
* +"aabbbb"+
* +"abbaabab"+

===== Caracteres especiais `+` e `?`

Ja vimos que o caractere especial `*` representa zero ou mais repetições de 
um padrão. O caractere especial `+` é similar, mas representa uma ou mais 
repetições; a única diferença é que o caractere `+` causa a obrigatoriedade 
de pelo menos uma repetição do padrão. A expressão `a+` representa as _strings_ 
`"a"`, `"aa"`, `"aaa"`, etc., sem incluir a _string_ vazia. 

O caractere especial `?` representa partes opcionais em um padrão, ou seja, 
zero ou uma repetição de um determinado padrão. A expressão `b?a+` representa 
_strings_ com uma ou mais repetições de +a+, podendo começar opcionalmente com 
um +b+. 

===== Classes de caracteres, intervalos e negação

As classes de caracteres são uma notação adicional para representar opções de 
um caractere em um padrão. A classe +[abc]+ representa apenas um caractere, que 
pode ser +a+, +b+ ou +c+. Isso é o mesmo que a expressão `(a|b|c)`, e a notação 
de classes é apenas um atalho, principalmente quando existem várias opções. 

A expressão `[0123456789]` representa um caractere que é um dígito numérico. 
Adicionando um caractere de repetição temos `[0123456789]+`, que representa 
_strings_ contendo um ou mais dígitos. Essas são exatamente as _strings_, 
como `"145"` ou `"017"`, que representam constantes inteiras. 

Quando uma classe inclui vários caracteres em uma sequência, como o exemplo 
anterior, podemos usar _intervalos_ para tornar as expressões mais compactas. 
Por exemplo, a expressão `[0123456789]` pode ser igualmente representada 
pelo intervalo `[0-9]`. A expressão `[a-z]` representa uma letra minúscula. 
Podemos usar vários intervalos em uma classe. Por exemplo, `[A-Za-z]` 
representa uma letra maiúscula ou minúscula, e `[0-9A-Za-z]` representa 
um dígito ou letra. Note que cada classe ainda representa apenas um caractere; 
os intervalos apenas criam novas opções para esse caractere. 

Uma outra notação útil com classes é a negação. Usar um caractere `^` no começo 
de uma classe representa ``caracteres que não estão na classe''. Por exemplo, 
`[^0-9]` representa um caractere que não é um dígito de `0` a `9`. 

===== Metacaracteres

Um outro tipo de caracteres especiais são os _metacaracteres_. 

=== Geradores de Analisadores Léxicos

Entrada e saída. 

=== Uso do flex

Formato da entrada, etc. 

